"""
Textual-based Asynchronous Python Web Vulnerability Scanner
-----------------------------------------------------------
Updated for Python 3.10+ and Textual 0.20+.

Installation:
-------------
1. python -m venv .venv
2. source .venv/bin/activate (or .venv\Scripts\activate on Windows)
3. pip install textual aiohttp beautifulsoup4 playwright
4. playwright install  (if using --enable-dom-xss in original script)

Run the TUI:
------------
python vuln_scanner_textual.py

Features:
---------
1. Asynchronous crawling with asyncio + aiohttp (queue-based).
2. SQL Injection testing, reflected XSS, and optional DOM-based XSS via Playwright.
3. CSRF checks with warning when tokens are missing.
4. Max depth argument to limit crawling depth.
5. Exclusion list for skipping certain paths or URLs.
6. Custom user-agent setting.
7. Real-time logging panel within Textual.
8. Results panel listing all vulnerabilities discovered.

Disclaimer:
-----------
Use only on targets you have explicit permission to scan.
Unauthorized scanning may be illegal.
"""

import asyncio
import aiohttp
import json
import re
from typing import Optional, List, Set, Dict, Tuple
from urllib.parse import urljoin, urlparse

from bs4 import BeautifulSoup

# For DOM-based XSS detection (optional if user wants it and has playwright installed)
try:
    from playwright.async_api import async_playwright
except ImportError:
    async_playwright = None

# ---- Textual Imports (for 0.20+) ----
from textual.app import App, ComposeResult
from textual.containers import VerticalScroll
from textual.widgets import (
    Header,
    Footer,
    Static,
    Button,
    Input,
    Checkbox,
    DataTable,
)

# --------------------- Payloads & Signatures ----------------------
SQL_PAYLOADS = [
    "' OR 1=1 --",
    "' UNION SELECT NULL,NULL,NULL --",
    "'; DROP TABLE users; --",
    '" OR 1=1 --',
    "admin' --",
]

XSS_PAYLOADS = [
    "<script>alert('XSS')</script>",
    "\"/><script>alert('XSS')</script>",
    "'\"><img src=x onerror=alert('XSS')>",
]

OTHER_PAYLOADS = [
    # LDAP injection, command injection, SSRF placeholders, etc.
    "*)(|(objectClass=*))",  # Example LDAP injection
    "|| ping -c 4 127.0.0.1 ||",  # Example command injection
]

SQL_ERROR_SIGNATURES = [
    "You have an error in your SQL syntax",
    "Warning: mysql_",
    "Warning: pg_",
    "Unclosed quotation mark after the character string",
    "SQL syntax error",
]


class AsyncWebVulnerabilityScanner:
    """
    Asynchronous web vulnerability scanner with BFS-based crawling,
    injection payload testing, optional DOM-based XSS checks, and more.
    """

    def __init__(
        self,
        base_url: str,
        max_concurrency: int = 5,
        enable_dom_xss: bool = False,
        disable_csrf_check: bool = False,
        max_depth: int = 3,
        exclude_urls: Optional[List[str]] = None,
        user_agent: Optional[str] = None,
        log_callback=None,
    ) -> None:
        """
        Args:
            base_url: The starting URL for scanning.
            max_concurrency: Limit for concurrent aiohttp requests.
            enable_dom_xss: Whether to check for DOM-based XSS with Playwright.
            disable_csrf_check: If True, CSRF checks will be skipped.
            max_depth: Maximum crawl depth.
            exclude_urls: List of substrings to exclude from crawling.
            user_agent: Custom User-Agent header.
            log_callback: A callable that takes a str to log messages into the TUI.
        """
        self.base_url = base_url
        self.max_concurrency = max_concurrency
        self.semaphore = asyncio.Semaphore(max_concurrency)

        self.enable_dom_xss = enable_dom_xss
        self.disable_csrf_check = disable_csrf_check
        self.max_depth = max_depth

        self.exclude_urls = [p.lower() for p in (exclude_urls or [])]
        self.headers = {}
        if user_agent:
            self.headers["User-Agent"] = user_agent

        self.visited_urls: Set[str] = set()
        self.results: List[str] = []

        # Queue for BFS-based scanning: holds (url, depth)
        self.url_queue: asyncio.Queue[Tuple[str, int]] = asyncio.Queue()
        self.url_queue.put_nowait((base_url, 0))

        # Function to call for logging into the TUI
        self.append_log = log_callback or (lambda msg: None)

    def is_same_domain(self, url: str) -> bool:
        """Check if `url` is within the same domain as `self.base_url`."""
        return urlparse(url).netloc == urlparse(self.base_url).netloc

    def should_exclude(self, url: str) -> bool:
        """Return True if the URL should be excluded based on patterns."""
        return any(pattern in url.lower() for pattern in self.exclude_urls)

    async def fetch(
        self,
        session: aiohttp.ClientSession,
        url: str,
        method: str = "GET",
        data: Optional[Dict[str, str]] = None,
        timeout: int = 10,
    ) -> Tuple[Optional[str], Optional[int]]:
        """
        Fetch URL using aiohttp, with concurrency managed by semaphore.
        Returns (text, status_code); (None, None) on failure.
        """
        async with self.semaphore:
            try:
                if method.upper() == "POST":
                    async with session.post(url, data=data, timeout=timeout) as resp:
                        text = await resp.text()
                        return text, resp.status
                else:
                    async with session.get(url, params=data, timeout=timeout) as resp:
                        text = await resp.text()
                        return text, resp.status
            except Exception as e:
                self.append_log(f"[DEBUG] Error fetching {url}: {e}")
                return None, None

    async def crawl_url(
        self, session: aiohttp.ClientSession, url: str, depth: int
    ) -> None:
        """Crawl a single URL: parse forms, test vulnerabilities, discover new links."""
        if url in self.visited_urls:
            return
        self.visited_urls.add(url)

        self.append_log(f"[*] Crawling (depth={depth}): {url}")
        html, status = await self.fetch(session, url)
        if not html or status != 200:
            self.append_log(f"[DEBUG] Skipping URL {url}, status={status}")
            return

        soup = BeautifulSoup(html, "html.parser")

        # 1. Analyze forms & test for vulnerabilities
        await self.test_forms(session, url, soup)

        # 2. CSRF checks if not disabled
        if not self.disable_csrf_check:
            self.check_csrf_tokens(url, soup)

        # 3. Discover new links if within depth limit
        if depth < self.max_depth:
            self.discover_links(soup, url, depth + 1)

    def discover_links(
        self, soup: BeautifulSoup, base_url: str, next_depth: int
    ) -> None:
        """Discover and enqueue new links from the page for further crawling."""
        for link in soup.find_all("a", href=True):
            full_link = urljoin(base_url, link["href"])
            if (
                self.is_same_domain(full_link)
                and not self.should_exclude(full_link)
                and full_link not in self.visited_urls
            ):
                self.append_log(
                    f"[DEBUG] Discovered link: {full_link} (depth={next_depth})"
                )
                self.url_queue.put_nowait((full_link, next_depth))

    def check_csrf_tokens(self, page_url: str, soup: BeautifulSoup) -> None:
        """
        Basic check for CSRF tokens in forms:
        - Looks for hidden inputs with 'csrf' in their name attribute.
        """
        for form in soup.find_all("form"):
            hidden_inputs = form.find_all("input", {"type": "hidden"})
            csrf_tokens = [
                inp
                for inp in hidden_inputs
                if re.search("csrf", inp.get("name", ""), re.IGNORECASE)
            ]
            if not csrf_tokens:
                msg = f"[!] Potential missing CSRF token on {page_url} (action={form.get('action')})"
                self.append_log(msg)
                self.results.append(msg)

    async def test_forms(
        self,
        session: aiohttp.ClientSession,
        page_url: str,
        soup: BeautifulSoup,
    ) -> None:
        """
        Extract forms, gather inputs, and submit payloads for SQLi, XSS, and other attacks.
        """
        for form in soup.find_all("form"):
            action = form.get("action") or ""
            method = form.get("method", "get").upper()
            target_url = urljoin(page_url, action)

            inputs = form.find_all(["input", "textarea"])
            input_names = [inp.get("name") for inp in inputs if inp.get("name")]

            # Test each category of payload
            for category, payloads in [
                ("SQL Injection", SQL_PAYLOADS),
                ("XSS", XSS_PAYLOADS),
                ("Other Injection", OTHER_PAYLOADS),
            ]:
                for payload in payloads:
                    form_data = {name: payload for name in input_names}
                    await self.submit_form(
                        session, target_url, method, form_data, category
                    )

    async def submit_form(
        self,
        session: aiohttp.ClientSession,
        url: str,
        method: str,
        data: Dict[str, str],
        vuln_type: str,
    ) -> None:
        """Submit a form with a payload and perform checks for vulnerability signatures."""
        html, status = await self.fetch(session, url, method=method, data=data)
        if not html or status is None:
            return

        if vuln_type == "SQL Injection":
            for signature in SQL_ERROR_SIGNATURES:
                if signature.lower() in html.lower():
                    msg = f"[!] Possible SQL Injection at {url} with payload={data}"
                    self.append_log(msg)
                    self.results.append(msg)
                    return

        elif vuln_type == "XSS":
            # Check if payload is reflected in the response
            for val in data.values():
                if val in html:
                    msg = f"[!] Possible Reflected XSS at {url} with payload='{val}'"
                    self.append_log(msg)
                    self.results.append(msg)
                    return

    async def detect_dom_xss(self) -> None:
        """
        Use Playwright to detect DOM-based XSS by injecting payloads as query parameters.
        """
        if not async_playwright:
            self.append_log(
                "[ERROR] Playwright is not installed. Skipping DOM-based XSS."
            )
            return

        candidate_urls = [u for u in self.visited_urls if self.is_same_domain(u)]
        self.append_log("[+] Starting DOM-based XSS detection...")

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context()

            for url in candidate_urls:
                for payload in XSS_PAYLOADS:
                    test_url = self.append_payload_to_url(url, payload)
                    self.append_log(f"[DEBUG] Testing DOM-based XSS on {test_url}")

                    page = await context.new_page()

                    async def on_dialog(dialog):
                        msg = f"[!] Possible DOM XSS at {test_url}. Dialog text: {dialog.message}"
                        self.append_log(msg)
                        self.results.append(msg)
                        await dialog.dismiss()

                    page.on("dialog", on_dialog)

                    try:
                        await page.goto(test_url, timeout=10000)
                        # Let scripts run
                        await asyncio.sleep(2)
                    except Exception as e:
                        self.append_log(
                            f"[DEBUG] DOM XSS test failed at {test_url}: {e}"
                        )
                    finally:
                        await page.close()

            await context.close()
            await browser.close()

    @staticmethod
    def append_payload_to_url(url: str, payload: str) -> str:
        """Append an XSS payload as a query parameter for DOM XSS testing."""
        if "?" in url:
            return f"{url}&xss={payload}"
        return f"{url}?xss={payload}"

    async def run(self) -> List[str]:
        """
        Main scan loop: connect, crawl all pages in BFS manner, optionally check DOM XSS.
        Returns the list of discovered vulnerabilities.
        """
        conn = aiohttp.TCPConnector(ssl=False)  # Optionally ignore SSL for testing
        async with aiohttp.ClientSession(
            connector=conn, headers=self.headers
        ) as session:
            while not self.url_queue.empty():
                url, depth = await self.url_queue.get()
                await self.crawl_url(session, url, depth)

        if self.enable_dom_xss:
            await self.detect_dom_xss()

        return self.results


# --------------------- Textual TUI App ----------------------
class VulnScannerApp(App):
    """
    A Textual TUI for configuring and running the AsyncWebVulnerabilityScanner.
    """

    CSS = """
    Screen {
        layout: grid;
        grid-size: 3;
        grid-rows: 3;
        grid-columns: 3;
    }

    #controls-panel {
        column-span: 3;
        row: 1;
        border: solid white;
        padding: 1;
    }

    #log-panel {
        column: 1 / span 3;
        row: 2;
        border: solid green;
    }

    #results-panel {
        column: 1 / span 3;
        row: 3;
        border: solid yellow;
    }
    """

    def compose(self) -> ComposeResult:
        """Create the UI layout."""
        yield Header(show_clock=True)
        yield Static("Configure Scanner", id="controls-panel")
        yield VerticalScroll(Static("Log Output:\n"), id="log-panel")
        yield DataTable(id="results-panel")
        yield Footer()

    def on_mount(self) -> None:
        """
        Dynamically add form controls to the controls panel.
        """
        controls_panel = self.query_one("#controls-panel", Static)

        # Intro text
        controls_panel.update("Enter Scan Configuration Below:\n")

        # We'll store references to our widgets so we can read values later
        self.url_input = Input(placeholder="https://example.com", name="url")
        self.concurrency_input = Input(
            placeholder="Max Concurrency (default=5)", name="max_concurrency"
        )
        self.depth_input = Input(placeholder="Max Depth (default=3)", name="max_depth")
        self.exclude_input = Input(
            placeholder="Comma-separated excludes", name="exclude_urls"
        )
        self.user_agent_input = Input(
            placeholder="Custom User-Agent", name="user_agent"
        )

        self.dom_xss_checkbox = Checkbox(label="Enable DOM XSS?")
        self.csrf_checkbox = Checkbox(label="Disable CSRF Check?")
        self.run_button = Button("Run Scan", id="run_button")

        # Insert them into the same container
        controls_panel.update(
            Static("Target URL:"),
            self.url_input,
            Static("Max Concurrency:"),
            self.concurrency_input,
            Static("Max Depth:"),
            self.depth_input,
            Static("Exclude URLs:"),
            self.exclude_input,
            Static("User-Agent:"),
            self.user_agent_input,
            self.dom_xss_checkbox,
            self.csrf_checkbox,
            self.run_button,
        )

        # Configure our results table
        results_panel = self.query_one("#results-panel", DataTable)
        results_panel.show_header = True
        results_panel.show_row_labels = False
        results_panel.add_column("Findings")

    def append_log(self, message: str) -> None:
        """
        Append a log message to the 'log-panel' widget without
        overriding Textual's built-in logger.
        """
        log_panel = self.query_one("#log-panel", VerticalScroll)
        log_panel.update(log_panel.renderable + f"\n{message}")

    async def on_button_pressed(self, event: Button.Pressed) -> None:
        """
        Handle the "Run Scan" button press: gather config, start scanning in the background.
        """
        if event.button.id == "run_button":
            # Read config from inputs
            url = self.url_input.value.strip()
            concurrency_str = self.concurrency_input.value.strip() or "5"
            depth_str = self.depth_input.value.strip() or "3"
            exclude_str = self.exclude_input.value.strip()
            user_agent_str = self.user_agent_input.value.strip()

            enable_dom_xss = self.dom_xss_checkbox.value
            disable_csrf = self.csrf_checkbox.value

            # Convert concurrency/depth to int safely
            try:
                max_concurrency = int(concurrency_str)
            except ValueError:
                max_concurrency = 5

            try:
                max_depth = int(depth_str)
            except ValueError:
                max_depth = 3

            exclude_list = []
            if exclude_str:
                exclude_list = [x.strip() for x in exclude_str.split(",") if x.strip()]

            # Validate URL quickly
            if not url.lower().startswith("http"):
                self.append_log("[ERROR] Please provide a valid URL (http or https).")
                return

            # Instantiate scanner
            self.append_log(f"[INFO] Starting scan on {url} ...")
            scanner = AsyncWebVulnerabilityScanner(
                base_url=url,
                max_concurrency=max_concurrency,
                enable_dom_xss=enable_dom_xss,
                disable_csrf_check=disable_csrf,
                max_depth=max_depth,
                exclude_urls=exclude_list,
                user_agent=user_agent_str if user_agent_str else None,
                log_callback=self.append_log,
            )

            # Run the scan asynchronously
            results = await self.run_scanner(scanner)

            # Update results table
            results_table = self.query_one("#results-panel", DataTable)
            results_table.clear()  # Clear old data
            results_table.add_column("Findings")

            if results:
                for finding in results:
                    results_table.add_row(finding)
            else:
                results_table.add_row("No major findings.")

    async def run_scanner(self, scanner: AsyncWebVulnerabilityScanner) -> List[str]:
        """
        Execute the scanner in an async-friendly manner within Textual.
        """
        results = await scanner.run()
        self.append_log("[INFO] Scan complete.")
        return results


if __name__ == "__main__":
    # Start the Textual TUI
    VulnScannerApp().run()
